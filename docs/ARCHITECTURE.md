# RAG Architecture Overview

## System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ROBOT VOICE PIPELINE                         â”‚
â”‚                         with RAG                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Microphoneâ”‚â”€â”€â”€â”€â”€â–¶â”‚ Audio Captureâ”‚â”€â”€â”€â”€â”€â–¶â”‚ Speech-to-  â”‚
â”‚   (Input)   â”‚      â”‚   (16kHz)    â”‚      â”‚    Text     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚(AssemblyAI) â”‚
                                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                                                   â–¼
                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                          â”‚  User Query    â”‚
                                          â”‚  "Who is HOD?" â”‚
                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                                                  â”‚
                        â–¼                                                  â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   RAG Database        â”‚                        â”‚   Prompt Generator â”‚
            â”‚   (ChromaDB)          â”‚                        â”‚  (System Prompt)   â”‚
            â”‚                       â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚  â€¢ 61 chunks          â”‚                                  â”‚
            â”‚  â€¢ OpenAI Embeddings  â”‚                                  â”‚
            â”‚  â€¢ Semantic Search    â”‚                                  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
                       â”‚                                                â”‚
                       â”‚ Retrieve Top-3 Chunks                         â”‚
                       â”‚                                                â”‚
                       â–¼                                                â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                  â”‚
            â”‚  Context:             â”‚                                  â”‚
            â”‚  "HOD is Dr.          â”‚                                  â”‚
            â”‚   Thayaparan..."      â”‚                                  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â”‚
                       â”‚                                                â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚   AI Agent     â”‚
                                  â”‚ (GPT-4o-mini)  â”‚
                                  â”‚                â”‚
                                  â”‚ â€¢ Uses Context â”‚
                                  â”‚ â€¢ Generates    â”‚
                                  â”‚   Response     â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚    Response    â”‚
                                  â”‚ "The HOD is    â”‚
                                  â”‚ Dr. Thayaparan â”‚
                                  â”‚  Subramaniam." â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚ Text-to-Speech â”‚
                                  â”‚  (Cartesia)    â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                                           â–¼
                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                  â”‚ Audio Playback â”‚
                                  â”‚   (Speakers)   â”‚
                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Data Flow

### 1. Document Indexing (One-time Setup)

```
Documents (.txt files)
    â”‚
    â”œâ”€â–¶ Load from src/vector_database_documents/
    â”‚
    â”œâ”€â–¶ Split into chunks (1000 chars, 200 overlap)
    â”‚
    â”œâ”€â–¶ Generate embeddings (OpenAI text-embedding-3-small)
    â”‚
    â””â”€â–¶ Store in ChromaDB (./chroma_db/)
```

### 2. Query Processing (Runtime)

```
User Query
    â”‚
    â”œâ”€â–¶ Generate query embedding
    â”‚
    â”œâ”€â–¶ Semantic search in ChromaDB
    â”‚
    â”œâ”€â–¶ Retrieve top-K similar chunks (K=3)
    â”‚
    â”œâ”€â–¶ Format as context string
    â”‚
    â””â”€â–¶ Inject into AI prompt
         â”‚
         â”œâ”€â–¶ System Prompt (Robot Profile)
         â”œâ”€â–¶ Retrieved Context (RAG)
         â”œâ”€â–¶ Chat History
         â””â”€â–¶ User Query
              â”‚
              â””â”€â–¶ Generate Response
```

## Components

### Core Modules

| Module | Purpose | Technology |
|--------|---------|------------|
| **rag_database.py** | Vector DB management | ChromaDB, LangChain |
| **ai_agent.py** | LLM orchestration | OpenAI GPT-4o-mini |
| **prompt_templates.py** | Prompt engineering | Custom templates |
| **main.py** | Pipeline orchestration | AsyncIO |

### Storage

```
robot-voice-pipeline/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ vector_database_documents/    # Source documents (9 files)
â”‚       â”œâ”€â”€ ENTC_Introduction.txt
â”‚       â”œâ”€â”€ Academic_Programs.txt
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ chroma_db/                         # Vector database
    â”œâ”€â”€ chroma.sqlite3                 # Metadata
    â””â”€â”€ [embedding vectors]            # Stored embeddings
```

## RAG Pipeline Details

### Embedding Generation

```python
# Using OpenAI text-embedding-3-small
Document â†’ Chunks â†’ Embeddings (1536 dimensions)
                        â†“
                   ChromaDB Storage
```

### Retrieval Process

```python
Query â†’ Embedding â†’ Cosine Similarity â†’ Top-K Chunks
                                             â†“
                                    Formatted Context
```

### Context Injection

```python
System Prompt = f"""
    ROBOT PROFILE: {robot_profile}
    
    RETRIEVED KNOWLEDGE:
    {rag_context}  # â† Injected from ChromaDB
    
    RULES: {rules}
    
    USER QUERY: {user_input}
"""
```

## Performance Metrics

| Metric | Value | Notes |
|--------|-------|-------|
| **Documents** | 9 | .txt files |
| **Total Chunks** | 61 | 1000 chars each |
| **Embedding Dim** | 1536 | OpenAI model |
| **Retrieval Time** | ~50-100ms | Per query |
| **Accuracy Gain** | High | For domain questions |
| **Storage** | ~5MB | ChromaDB |

## Configuration Options

### RAG Parameters

```python
# Chunking
chunk_size = 1000          # Characters per chunk
chunk_overlap = 200        # Overlap for context

# Retrieval
k = 3                      # Number of chunks to retrieve
max_context_length = 2000  # Max chars in context

# Embeddings
model = "text-embedding-3-small"  # OpenAI model
```

### Toggle RAG

```python
# Enable RAG (default)
agent = AIAgent(rag_database=rag_db, use_rag=True)

# Disable RAG
agent = AIAgent(rag_database=None, use_rag=False)
```

## Dependencies

```toml
langchain-chroma      # ChromaDB integration
chromadb              # Vector database
langchain-text-splitters  # Document chunking
langchain-openai      # OpenAI integration
```

## API Calls

### Initialization (One-time)
- **OpenAI Embeddings API**: 61 chunks Ã— ~250 tokens = ~15,250 tokens
- **Cost**: ~$0.001

### Per Query (Runtime)
- **OpenAI Embeddings API**: 1 query embedding (~10-50 tokens)
- **OpenAI Chat API**: 1 completion (prompt + response)
- **Cost**: ~$0.0001-0.0005 per query

## Error Handling

```python
try:
    # Retrieve context
    context = rag_db.get_context_string(query)
except Exception as e:
    # Fallback to no context
    context = ""
    print(f"RAG retrieval failed: {e}")

# AI agent proceeds with or without context
response = agent.think(query)
```

## Future Enhancements

- [ ] Add metadata filtering (by document type, date, etc.)
- [ ] Implement hybrid search (keyword + semantic)
- [ ] Add document update tracking
- [ ] Support for PDF/DOCX documents
- [ ] Multi-language support
- [ ] Citation tracking (which document answered)
- [ ] Real-time document updates without restart

---

**Built with:**
- ğŸ§  LangChain for RAG orchestration
- ğŸ“š ChromaDB for vector storage
- ğŸ¤– OpenAI for embeddings & LLM
- ğŸ™ï¸ AssemblyAI for speech-to-text
- ğŸ”Š Cartesia for text-to-speech
