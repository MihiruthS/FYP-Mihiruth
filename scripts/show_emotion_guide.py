"""
Visual demonstration of emotion display system.

Shows how different emotions look on the robot's face (via servo positions).
Useful for testing and calibrating facial expressions.
"""

import sys
from pathlib import Path

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent / "src"))


def display_emotion_guide():
    """Display a guide showing all emotions and their servo positions."""
    
    print("\n" + "="*70)
    print("  ROBOT EMOTION DISPLAY GUIDE")
    print("="*70 + "\n")
    
    emotions = {
        "neutral": {
            "description": "Calm, informational, factual responses",
            "eyes": "Normal open position",
            "upper_lid": "1200*4",
            "lower_lid": "1120*4",
            "example": "The computer lab is on the second floor."
        },
        "joy": {
            "description": "Happy, positive, enthusiastic",
            "eyes": "Slightly narrowed (smiling eyes)",
            "upper_lid": "1400*4",
            "lower_lid": "1300*4",
            "example": "I'm so glad I could help you!"
        },
        "fear": {
            "description": "Worried, anxious, uncertain",
            "eyes": "Wide open",
            "upper_lid": "900*4",
            "lower_lid": "1000*4",
            "example": "I'm not sure about this situation."
        },
        "disgust": {
            "description": "Disapproval, unpleasant topics",
            "eyes": "Narrowed with squint",
            "upper_lid": "1500*4",
            "lower_lid": "1350*4",
            "example": "That's quite unpleasant."
        },
        "sadness": {
            "description": "Sad, disappointed, apologetic",
            "eyes": "Drooped eyelids",
            "upper_lid": "1600*4",
            "lower_lid": "1200*4",
            "example": "I'm sorry to hear that."
        },
        "anger": {
            "description": "Frustrated, annoyed, stern",
            "eyes": "Very narrowed and intense",
            "upper_lid": "1700*4",
            "lower_lid": "1400*4",
            "example": "This is completely unacceptable!"
        },
        "surprise": {
            "description": "Unexpected, amazed, shocked",
            "eyes": "Very wide open",
            "upper_lid": "800*4",
            "lower_lid": "900*4",
            "example": "Wow! That's incredible!"
        }
    }
    
    for emotion, details in emotions.items():
        print(f"â”Œâ”€ {emotion.upper()}")
        print(f"â”‚")
        print(f"â”‚  Description: {details['description']}")
        print(f"â”‚  Eyes:        {details['eyes']}")
        print(f"â”‚  Upper Lid:   Channel 14 â†’ {details['upper_lid']}")
        print(f"â”‚  Lower Lid:   Channel 15 â†’ {details['lower_lid']}")
        print(f"â”‚")
        print(f"â”‚  Example: \"{details['example']}\"")
        print(f"â””" + "â”€"*68 + "\n")
    
    print("="*70)
    print("\nğŸ’¡ CALIBRATION TIPS:")
    print("   - Adjust servo positions in mouth_controller.py")
    print("   - Higher upper_lid = eyes more closed")
    print("   - Lower lower_lid = eyes more open")
    print("   - Test with: mouth_controller.set_emotion('emotion_name')")
    print("\n" + "="*70 + "\n")


def display_pipeline_flow():
    """Display the emotion processing pipeline flow."""
    
    print("\n" + "="*70)
    print("  EMOTION PROCESSING PIPELINE")
    print("="*70 + "\n")
    
    flow = """
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  USER QUERY                                                     â”‚
    â”‚  "Where is the computer lab?"                                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  AI AGENT (thinks & generates response)                          â”‚
    â”‚  "The computer lab is on the second floor..."                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â”‚ (response text stream)
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  PIPELINE: _stream_response()                                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
    â”‚  â”‚ After 20+ chars:    â”‚    â”‚ Main Path (no blocking):    â”‚    â”‚
    â”‚  â”‚                     â”‚    â”‚                              â”‚    â”‚
    â”‚  â”‚ asyncio.create_task â”‚    â”‚ â€¢ TTS Synthesis             â”‚    â”‚
    â”‚  â”‚   (Emotion          â”‚    â”‚ â€¢ Audio Playback            â”‚    â”‚
    â”‚  â”‚    Classification)  â”‚    â”‚ â€¢ Mouth Sync                â”‚    â”‚
    â”‚  â”‚                     â”‚    â”‚                              â”‚    â”‚
    â”‚  â”‚ RUNS IN PARALLEL â”â”â”â”â”â”â”â”â–¶ NO LATENCY ADDED            â”‚    â”‚
    â”‚  â”‚ (background task)   â”‚    â”‚                              â”‚    â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
                 â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  EMOTION CLASSIFIER (async)                                      â”‚
    â”‚  â€¢ Calls OpenAI API (~200-500ms)                                 â”‚
    â”‚  â€¢ Classifies: "neutral"                                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  MOUTH CONTROLLER                                                â”‚
    â”‚  â€¢ set_emotion("neutral")                                        â”‚
    â”‚  â€¢ Updates servo positions:                                      â”‚
    â”‚    - Upper lid: 1200*4                                           â”‚
    â”‚    - Lower lid: 1120*4                                           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  ROS2 NODE                                                       â”‚
    â”‚  â€¢ Publishes to /motor_pos                                       â”‚
    â”‚  â€¢ Physical servos move                                          â”‚
    â”‚  â€¢ Face displays neutral expression                              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    â±ï¸  TOTAL LATENCY ADDED TO SPEECH: 0ms
    
    The robot starts speaking immediately while emotion classification
    happens in the background. The face updates during speech without
    interrupting audio playback.
    """
    
    print(flow)
    print("="*70 + "\n")


def display_timing_diagram():
    """Display timing diagram showing parallel execution."""
    
    print("\n" + "="*70)
    print("  TIMING DIAGRAM: Zero Latency Design")
    print("="*70 + "\n")
    
    timing = """
    Timeline (milliseconds) â†’
    
    0ms    500ms   1000ms  1500ms  2000ms  2500ms  3000ms
    â”‚      â”‚       â”‚       â”‚       â”‚       â”‚       â”‚
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
    â”‚ SPEECH SYNTHESIS & PLAYBACK (main path)
    â”‚ â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“â–“
    â”‚ Audio starts at 0ms (NO DELAY)
    â”‚
    â”‚
    â”œâ”€â”€â”€â”€â” (20 chars available)
    â”‚    â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º
    â”‚    EMOTION CLASSIFICATION (background task)
    â”‚    â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘
    â”‚    Classifies: ~200-500ms
    â”‚    Updates face during speech
    â”‚
    â”‚
    â”‚ âœ… Result: Robot speaks at 0ms, face updates at ~200ms
    â”‚    (during ongoing speech, no interruption)
    
    
    COMPARISON:
    
    âŒ Blocking Approach (adds latency):
    â”‚
    0msâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€500msâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€3000ms
    â”‚              â”‚               â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤               
    â”‚ WAIT FOR     â”‚               
    â”‚ EMOTION      â”‚               
    â”‚ (500ms)      â”‚               
    â”‚              â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚              â”‚ SPEECH        â”‚
    â”‚              â”‚ (starts late) â”‚
    â”‚              â”‚               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Speech delayed by 500ms! âŒ
    
    
    âœ… Async Approach (zero latency):
    â”‚
    0msâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€3000ms
    â”‚                              â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ SPEECH (starts immediately)  â”‚
    â”œâ”€â”€â”€â”€â”                         â”‚
    â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              
    â”‚ EMOTION       â”‚              
    â”‚ (parallel)    â”‚              
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    
    Speech starts at 0ms! âœ…
    """
    
    print(timing)
    print("="*70 + "\n")


if __name__ == "__main__":
    display_emotion_guide()
    display_pipeline_flow()
    display_timing_diagram()
    
    print("\nğŸ’¡ To test emotions:")
    print("   python scripts/test_emotions.py")
    print("\nğŸ’¡ To run with full pipeline:")
    print("   python src/robot_pipeline/ros2_main.py")
    print()
